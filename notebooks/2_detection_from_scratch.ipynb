{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jupyter Kernel**:\n",
    "\n",
    "* If you are in SageMaker Notebook instance, please make sure you are using **conda_pytorch_latest_p36** kernel\n",
    "* If you are on SageMaker Studio, please make sure you are using **SageMaker JumpStart PyTorch 1.0** kernel\n",
    "\n",
    "**Run All**:\n",
    "\n",
    "* If you are in SageMaker notebook instance, you can go to *Cell tab -> Run All*\n",
    "* If you are in SageMaker Studio, you can go to *Run tab -> Run All Cells*\n",
    "\n",
    "**Note**: To *Run All* successfully, make sure you have executed the entire demo notebook `0_demo.ipynb` first.\n",
    "\n",
    "## Training our Detector from Scratch\n",
    "\n",
    "In this notebook, we will see how to train our detector from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "sagemaker_config = json.load(open(\"../stack_outputs.json\"))\n",
    "role = sagemaker_config[\"IamRole\"]\n",
    "solution_bucket = sagemaker_config[\"SolutionS3Bucket\"]\n",
    "region = sagemaker_config[\"AWSRegion\"]\n",
    "solution_name = sagemaker_config[\"SolutionName\"]\n",
    "bucket = sagemaker_config[\"S3Bucket\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we download our **NEU-DET** dataset from our public S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_bucket = f\"s3://{solution_bucket}-{region}/{solution_name}\"\n",
    "original_pretained_checkpoint = f\"{original_bucket}/pretrained\"\n",
    "original_sources = f\"{original_bucket}/build/lib/source_dir.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for easiler data processing, we have already executed `prepare_data` once in our `0_demo.ipynb` and have already uploaded the prepared data to our S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = !echo $PWD/neu_det\n",
    "DATA_PATH = DATA_PATH.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After data preparation, we need to setup some paths that will be used throughtout the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = \"neu-det\"\n",
    "neu_det_s3 = f\"s3://{bucket}/{prefix}\"\n",
    "sources = f\"{neu_det_s3}/code/\"\n",
    "train_output = f\"{neu_det_s3}/output/\"\n",
    "neu_det_prepared_s3 = f\"{neu_det_s3}/data/\"\n",
    "s3_checkpoint = f\"{neu_det_s3}/checkpoint/\"\n",
    "sm_local_checkpoint_dir = \"/opt/ml/checkpoints/\"\n",
    "s3_pretrained = f\"{neu_det_s3}/pretrained/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Let examine some datasets that we will use later by providing an `ID`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "try:\n",
    "    import sagemaker_defect_detection\n",
    "except ImportError:\n",
    "    import sys\n",
    "    from pathlib import Path\n",
    "\n",
    "    ROOT = Path(\"../src\").resolve()\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "from sagemaker_defect_detection import NEUDET, get_preprocess\n",
    "\n",
    "SPLIT = \"test\"\n",
    "ID = 50\n",
    "dataset = NEUDET(DATA_PATH, split=SPLIT, preprocess=get_preprocess())\n",
    "images, targets, _ = dataset[ID]\n",
    "original_image = copy.deepcopy(images)\n",
    "original_boxes = targets[\"boxes\"].numpy().copy()\n",
    "original_labels = targets[\"labels\"].numpy().copy()\n",
    "print(f\"first images size: {original_image.shape}\")\n",
    "print(f\"target bounding boxes: \\n {original_boxes}\")\n",
    "print(f\"target labels: {original_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can now visualize it using the provided utilities as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker_defect_detection.utils.visualize import unnormalize_to_hwc, visualize\n",
    "\n",
    "original_image_unnorm = unnormalize_to_hwc(original_image)\n",
    "\n",
    "visualize(\n",
    "    original_image_unnorm,\n",
    "    [original_boxes],\n",
    "    [original_labels],\n",
    "    colors=[(255, 0, 0)],\n",
    "    titles=[\"original\", \"ground truth\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get high **Mean Average Percision (mAP)** and **Mean Average Recall (mAR)** for **Intersection Over Union (IOU)** thresholds of 0.5 when training from scratch, it requires more than **300 epochs**. That is why we have provided a pretrained model and recommend finetuning whenever is possible. For demostration, we train the model from scratch for 10 epochs which takes about **16 minutes** and it results in the following mAP, mAR and the accumulated `main_score` of\n",
    "\n",
    "* `Average Precision  (AP) @[ IoU=0.50:0.95 ] ~ 0.048`\n",
    "* `Average Recall     (AR) @[ IoU=0.50:0.95] ~ 0.153`\n",
    "* `main_score=0.0509`\n",
    "\n",
    "To get higher mAP, mAR and overall `main_score`, you can train for more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import logging\n",
    "from os import path as osp\n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "NUM_CLASSES = 7  # 6 classes + 1 for background\n",
    "BACKBONE = \"resnet34\"  # has to match the pretrained model backbone\n",
    "assert BACKBONE in [\n",
    "    \"resnet34\",\n",
    "    \"resnet50\",\n",
    "], \"either resnet34 or resnet50. Make sure to be consistent with model_fn in detector.py\"\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-3\n",
    "SEED = 123\n",
    "\n",
    "hyperparameters = {\n",
    "    \"backbone\": BACKBONE,  # the backbone resnet model for feature extraction\n",
    "    \"num-classes\": NUM_CLASSES,  # number of classes 6 + 1 background\n",
    "    \"epochs\": EPOCHS,  # number of epochs to train\n",
    "    \"learning-rate\": LEARNING_RATE,  # learning rate for optimizer\n",
    "    \"seed\": SEED,  # random number generator seed\n",
    "}\n",
    "\n",
    "model = PyTorch(\n",
    "    entry_point=\"detector.py\",\n",
    "    source_dir=osp.join(sources, \"source_dir.tar.gz\"),\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.g4dn.2xlarge\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    py_version=\"py3\",\n",
    "    framework_version=\"1.5\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    output_path=train_output,\n",
    "    checkpoint_s3_uri=s3_checkpoint,\n",
    "    checkpoint_local_path=sm_local_checkpoint_dir,\n",
    "    # container_log_level=logging.DEBUG,\n",
    ")\n",
    "\n",
    "model.fit(neu_det_prepared_s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we deploy our model which takes about **10 minutes** to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "detector = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    endpoint_name=sagemaker_config[\"SolutionPrefix\"] + \"-detector-from-scratch-endpoint\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "We change the input depending on whether we are providing a list of images or a single image. Also the model requires a four dimensional array / tensor (with the first dimension as batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = list(img.numpy() for img in images) if isinstance(images, list) else images.unsqueeze(0).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the input is ready and we can get some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# SageMaker 1.x doesn't allow_pickle=True by default\n",
    "np_load_old = np.load\n",
    "np.load = lambda *args, **kwargs: np_load_old(*args, allow_pickle=True, **kwargs)\n",
    "predictions = detector.predict(input)\n",
    "np.load = np_load_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use our `visualize` utility to check the detection results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(\n",
    "    original_image_unnorm,\n",
    "    [original_boxes, predictions[0][\"boxes\"]],\n",
    "    [original_labels, predictions[0][\"labels\"]],\n",
    "    colors=[(255, 0, 0), (0, 0, 255)],\n",
    "    titles=[\"original\", \"ground truth\", \"trained from scratch\"],\n",
    "    dpi=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to compare the results of the new model and the pretrained model that we already deployed in `0_demo.ipynb`  visually by calling our endpoint from SageMaker runtime using `boto3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "\n",
    "config = botocore.config.Config(read_timeout=200)\n",
    "runtime = boto3.client(\"runtime.sagemaker\", config=config)\n",
    "payload = json.dumps(input.tolist() if isinstance(input, np.ndarray) else input)\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=sagemaker_config[\"SolutionPrefix\"] + \"-demo-endpoint\", ContentType=\"application/json\", Body=payload\n",
    ")\n",
    "demo_predictions = json.loads(response[\"Body\"].read().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compare the results of the provided pretrained model and our trained from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(\n",
    "    original_image_unnorm,\n",
    "    [original_boxes, demo_predictions[0][\"boxes\"], predictions[0][\"boxes\"]],\n",
    "    [original_labels, demo_predictions[0][\"labels\"], predictions[0][\"labels\"]],\n",
    "    colors=[(255, 0, 0), (0, 0, 255), (127, 0, 127)],\n",
    "    titles=[\"original\", \"ground truth\", \"pretrained\", \"from scratch\"],\n",
    "    dpi=250,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Delete the endpoint and model\n",
    "\n",
    "When you are done with the endpoint, you should clean it up.\n",
    "\n",
    "All of the training jobs, models and endpoints we created can be viewed through the SageMaker console of your AWS account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.delete_model()\n",
    "detector.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Click here to continue](./3_classification_from_scratch.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('pytorch_latest_p36': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4c1e195df8d07db5ee7a78f454b46c3f2e14214bf8c9489d2db5cf8f372ff2ed"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}